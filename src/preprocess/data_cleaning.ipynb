{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7253408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tranh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tranh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tranh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\tranh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\tranh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21bb0665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng văn bản ban đầu: 2225\n",
      "\n",
      "Cột trong dataset: ['text', 'labels']\n",
      "\n",
      "Các nhãn: ['business' 'entertainment' 'politics' 'sport' 'tech']\n",
      "\n",
      "Phân bố nhãn:\n",
      "labels\n",
      "sport            511\n",
      "business         510\n",
      "politics         417\n",
      "tech             401\n",
      "entertainment    386\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data_use/bbc_text_cls.csv')\n",
    "\n",
    "print(f\"Số lượng văn bản ban đầu: {len(df)}\")\n",
    "print(f\"\\nCột trong dataset: {df.columns.tolist()}\")\n",
    "print(f\"\\nCác nhãn: {df['labels'].unique()}\")\n",
    "print(f\"\\nPhân bố nhãn:\\n{df['labels'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2054d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo các công cụ xử lý\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Hàm làm sạch văn bản\n",
    "    \"\"\"\n",
    "    # Chuyển về chữ thường\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Loại bỏ ký tự đặc biệt và dấu câu (chỉ giữ lại chữ cái và khoảng trắng)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Loại bỏ stopwords và lemmatization\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words and len(token) > 1:  # Loại bỏ từ có 1 ký tự\n",
    "            lemmatized = lemmatizer.lemmatize(token)\n",
    "            cleaned_tokens.append(lemmatized)\n",
    "    \n",
    "    # Ghép lại thành văn bản\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a9fb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Đang làm sạch dữ liệu...\n",
      "==================================================\n",
      "\n",
      "Thống kê độ dài văn bản (số từ):\n",
      "count    2225.000000\n",
      "mean      216.142022\n",
      "std       125.279657\n",
      "min        48.000000\n",
      "25%       140.000000\n",
      "50%       189.000000\n",
      "75%       267.000000\n",
      "max      2211.000000\n",
      "Name: word_count, dtype: float64\n",
      "\n",
      "Số văn bản có độ dài > 1000 từ (outliers): 7\n",
      "Số văn bản sau khi loại bỏ outliers: 2218\n",
      "\n",
      "Thống kê độ dài văn bản (số từ):\n",
      "count    2225.000000\n",
      "mean      216.142022\n",
      "std       125.279657\n",
      "min        48.000000\n",
      "25%       140.000000\n",
      "50%       189.000000\n",
      "75%       267.000000\n",
      "max      2211.000000\n",
      "Name: word_count, dtype: float64\n",
      "\n",
      "Số văn bản có độ dài > 1000 từ (outliers): 7\n",
      "Số văn bản sau khi loại bỏ outliers: 2218\n"
     ]
    }
   ],
   "source": [
    "# Áp dụng làm sạch dữ liệu\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Đang làm sạch dữ liệu...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Tính độ dài văn bản (số từ)\n",
    "df['word_count'] = df['cleaned_text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(f\"\\nThống kê độ dài văn bản (số từ):\")\n",
    "print(df['word_count'].describe())\n",
    "\n",
    "# Lọc văn bản có độ dài <= 1000 từ\n",
    "outliers_count = len(df[df['word_count'] > 1000])\n",
    "print(f\"\\nSố văn bản có độ dài > 1000 từ (outliers): {outliers_count}\")\n",
    "\n",
    "df_cleaned = df[df['word_count'] <= 1000].copy()\n",
    "print(f\"Số văn bản sau khi loại bỏ outliers: {len(df_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a64660cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Ví dụ văn bản gốc và văn bản đã làm sạch:\n",
      "==================================================\n",
      "\n",
      "Nhãn: business\n",
      "\n",
      "Gốc:\n",
      "Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\n",
      "\n",
      "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and highe...\n",
      "\n",
      "Đã làm sạch:\n",
      "ad sale boost time warner profit quarterly profit u medium giant timewarner jumped bn three month december yearearlier firm one biggest investor google benefited sale highspeed internet connection higher advert sale timewarner said fourth quarter sale rose bn bn profit buoyed oneoff gain offset prof...\n",
      "\n",
      "Số từ: 239\n",
      "\n",
      "==================================================\n",
      "Đã lưu dữ liệu đã làm sạch vào file: bbc_cleaned.csv\n",
      "==================================================\n",
      "\n",
      "Phân bố nhãn sau khi làm sạch:\n",
      "labels\n",
      "sport            511\n",
      "business         510\n",
      "politics         414\n",
      "tech             400\n",
      "entertainment    383\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Tỷ lệ giữ lại: 99.69%\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra kết quả\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ví dụ văn bản gốc và văn bản đã làm sạch:\")\n",
    "print(\"=\"*50)\n",
    "idx = 0\n",
    "print(f\"\\nNhãn: {df_cleaned.iloc[idx]['labels']}\")\n",
    "print(f\"\\nGốc:\\n{df_cleaned.iloc[idx]['text'][:300]}...\")\n",
    "print(f\"\\nĐã làm sạch:\\n{df_cleaned.iloc[idx]['cleaned_text'][:300]}...\")\n",
    "print(f\"\\nSố từ: {df_cleaned.iloc[idx]['word_count']}\")\n",
    "\n",
    "# Lưu dữ liệu đã làm sạch\n",
    "df_cleaned[['cleaned_text', 'labels']].to_csv('../../data_use/bbc_cleaned.csv', index=False)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Đã lưu dữ liệu đã làm sạch vào file: bbc_cleaned.csv\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Thống kê cuối cùng\n",
    "print(f\"\\nPhân bố nhãn sau khi làm sạch:\")\n",
    "print(df_cleaned['labels'].value_counts())\n",
    "print(f\"\\nTỷ lệ giữ lại: {len(df_cleaned)/len(df)*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-mhd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
